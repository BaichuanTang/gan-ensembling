{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "from networks import domain_generator, domain_classifier\n",
    "from utils import renormalize, show\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkmark = '\\u2713'\n",
    "crossmark = '\\u2717'\n",
    "\n",
    "def classify_image(image, classifier, label):\n",
    "    with torch.no_grad():\n",
    "        preds = domain_classifier.postprocess(classifier(image))\n",
    "        preds = preds.cpu().numpy()\n",
    "    if np.ndim(preds) == 1:\n",
    "        # binary prediction\n",
    "        acc = ((preds > 0.5).astype(int)) == label\n",
    "    elif np.ndim(preds) == 2:\n",
    "        acc = np.argmax(preds, axis=-1) == label\n",
    "        preds = preds[:, label]\n",
    "    return preds, acc\n",
    "\n",
    "def classify_from_gan(image, classifier, tensor_transform, label):\n",
    "    with torch.no_grad():\n",
    "        postprocessed_im = tensor_transform(image)\n",
    "        preds = domain_classifier.postprocess(classifier(postprocessed_im))\n",
    "        preds = preds.cpu().numpy()\n",
    "    if np.ndim(preds) == 1:\n",
    "        # binary prediction\n",
    "        acc = ((preds > 0.5).astype(int)) == label\n",
    "    elif np.ndim(preds) == 2:\n",
    "        acc = np.argmax(preds, axis=-1) == label\n",
    "        preds = preds[:, label]\n",
    "    return postprocessed_im, preds, acc\n",
    "\n",
    "def get_symbol(acc):\n",
    "    return checkmark if acc else crossmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stylegan2 generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_domain = 'cat'\n",
    "if target_domain == 'celebahq':\n",
    "    dataset_name = 'celebahq'\n",
    "    generator_name = 'stylegan2'\n",
    "    classifier_name = 'Smiling'\n",
    "    val_transform = data.get_transform(dataset_name, 'imval')\n",
    "    dset = data.get_dataset(dataset_name, 'val', classifier_name, load_w=True, transform=val_transform)\n",
    "    generator = domain_generator.define_generator(generator_name, dataset_name, load_encoder=False)\n",
    "    classifier = domain_classifier.define_classifier(dataset_name, classifier_name)\n",
    "    tensor_transform_val = data.get_transform(dataset_name, 'tensorbase') # centercrop to the appropriate dimension for classifier\n",
    "    tensor_transform_ensemble = data.get_transform(dataset_name, 'tensormixed') # alternatively, can just use tensorbase\n",
    "elif target_domain == 'car':\n",
    "    dataset_name = 'car'\n",
    "    generator_name = 'stylegan2'\n",
    "    classifier_name = 'latentclassifier_stylemix_fine'\n",
    "    val_transform = data.get_transform(dataset_name, 'imval')\n",
    "    dset = data.get_dataset(dataset_name, 'val', load_w=True, transform=val_transform)\n",
    "    generator = domain_generator.define_generator(generator_name, dataset_name, load_encoder=False)\n",
    "    classifier = domain_classifier.define_classifier(dataset_name, classifier_name)\n",
    "    tensor_transform_val = data.get_transform(dataset_name, 'tensorbase') # centercrop to the appropriate dimension for classifier\n",
    "    tensor_transform_ensemble = data.get_transform(dataset_name, 'tensormixed') # alternatively, can just use tensorbase\n",
    "elif target_domain == 'cat':\n",
    "    dataset_name = 'cat'\n",
    "    generator_name = 'stylegan2'\n",
    "    classifier_name = 'latentclassifier_stylemix_coarse'\n",
    "    val_transform = data.get_transform(dataset_name, 'imval')\n",
    "    dset = data.get_dataset(dataset_name, 'val', load_w=True, transform=val_transform)\n",
    "    generator = domain_generator.define_generator(generator_name, dataset_name, load_encoder=False)\n",
    "    classifier = domain_classifier.define_classifier(dataset_name, classifier_name)\n",
    "    tensor_transform_val = data.get_transform(dataset_name, 'tensorbase') # centercrop to the appropriate dimension for classifier\n",
    "    tensor_transform_ensemble = data.get_transform(dataset_name, 'tensormixed') # alternatively, can just use tensorbase\n",
    "else:\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "with torch.no_grad():\n",
    "    label = dset[index][2]\n",
    "    # original image prediction\n",
    "    pred_original, acc_original = classify_image(dset[index][0][None].cuda(), classifier, label)\n",
    "    show.a(['original: %0.2f %s' % (pred_original[0], get_symbol(acc_original[0])),\n",
    "            renormalize.as_image(dset[index][0]).resize((256, 256), Image.ANTIALIAS)])\n",
    "    \n",
    "    # gan reconstruction prediction\n",
    "    latent = dset[index][1][None].cuda()\n",
    "    reconstruction = generator.decode(latent)\n",
    "    postprocessed_rec, pred_rec, acc_rec = classify_from_gan(reconstruction, classifier, tensor_transform_val, label)\n",
    "    show.a(['reconstruction %0.2f %s' % (pred_rec[0], get_symbol(acc_rec[0])),\n",
    "            renormalize.as_image(postprocessed_rec[0]).resize((256, 256), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # isotropic fine\n",
    "    eps = np.max(generator.perturb_settings['isotropic_eps_fine'])\n",
    "    perturbed_im = generator.perturb_isotropic(latent, 'fine', eps=eps,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "        perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['isotropic fine %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # isotropic coarse\n",
    "    eps = np.max(generator.perturb_settings['isotropic_eps_coarse'])\n",
    "    perturbed_im = generator.perturb_isotropic(latent, 'coarse', eps=eps,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['isotropic coarse %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # pca fine\n",
    "    eps = np.max(generator.perturb_settings['pca_eps'])\n",
    "    perturbed_im = generator.perturb_pca(latent, 'fine', eps=eps,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['pca fine %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # pca coarse\n",
    "    eps = np.max(generator.perturb_settings['pca_eps'])\n",
    "    perturbed_im = generator.perturb_pca(latent, 'coarse', eps=eps,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['pca coarse %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # stylemix fine\n",
    "    mix_latent = generator.seed2w(n=4, seed=0)\n",
    "    perturbed_im = generator.perturb_stylemix(latent, 'fine', mix_latent,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['stylemix fine %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # stylemix coarse\n",
    "    mix_latent = generator.seed2w(n=4, seed=0)\n",
    "    perturbed_im = generator.perturb_stylemix(latent, 'coarse', mix_latent,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['stylemix coarse %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar10 generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_domain = 'cifar10'\n",
    "dataset_name = 'cifar10'\n",
    "generator_name = 'stylegan2-cc'\n",
    "classifier_name = 'imageclassifier'\n",
    "val_transform = data.get_transform(dataset_name, 'imval')\n",
    "dset = data.get_dataset(dataset_name, 'val', load_w=True, transform=val_transform)\n",
    "generator = domain_generator.define_generator(generator_name, dataset_name, load_encoder=False)\n",
    "classifier = domain_classifier.define_classifier(dataset_name, classifier_name)\n",
    "tensor_transform_val = data.get_transform(dataset_name, 'tensorbase') # centercrop to the appropriate dimension for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "with torch.no_grad():\n",
    "    label = dset[index][2]\n",
    "    # original image prediction\n",
    "    pred_original, acc_original = classify_image(dset[index][0][None].cuda(), classifier, label)\n",
    "    show.a(['original: %0.2f %s' % (pred_original[0], get_symbol(acc_original[0])),\n",
    "            renormalize.as_image(dset[index][0]).resize((256, 256), Image.ANTIALIAS)])\n",
    "    \n",
    "    # gan reconstruction prediction\n",
    "    latent = dset[index][1][None].cuda()\n",
    "    reconstruction = generator.decode(latent)\n",
    "    postprocessed_rec, pred_rec, acc_rec = classify_from_gan(reconstruction, classifier, tensor_transform_val, label)\n",
    "    show.a(['reconstruction %0.2f %s' % (pred_rec[0], get_symbol(acc_rec[0])),\n",
    "            renormalize.as_image(postprocessed_rec[0]).resize((256, 256), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # stylemix fine\n",
    "    # use predicted labels to generated class-conditional random samples\n",
    "    pred_original = domain_classifier.postprocess(classifier(dset[index][0][None].cuda()))\n",
    "    lab = torch.zeros([4, generator.generator.c_dim],\n",
    "                      device=generator.device)\n",
    "    _, pred_label = pred_original.max(1)\n",
    "    pred_label = pred_label.item()\n",
    "    lab[:, pred_label] = 1\n",
    "    mix_latent = generator.seed2w(seed=np.random.randint(1000), n=4, labels=lab)\n",
    "    perturbed_im = generator.perturb_stylemix(latent, 'fine', mix_latent,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_val, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['stylemix fine %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stylegan-idinvert generator\n",
    "\n",
    "NOTE: the pretrained generator and encoder needs to be downloaded before running the following blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'celebahq-idinvert'\n",
    "generator_name = 'stylegan-idinvert'\n",
    "classifier_name = 'Smiling'\n",
    "val_transform = data.get_transform(dataset_name, 'imval')\n",
    "dset = data.get_dataset(dataset_name, 'val', classifier_name, load_w=True, transform=val_transform)\n",
    "generator = domain_generator.define_generator(generator_name, dataset_name, load_encoder=False)\n",
    "classifier = domain_classifier.define_classifier(dataset_name, classifier_name)\n",
    "tensor_transform_val = data.get_transform(dataset_name, 'tensorbase') # centercrop to the appropriate dimension for classifier\n",
    "tensor_transform_ensemble = data.get_transform(dataset_name, 'tensormixed') # alternatively, can just use tensorbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "with torch.no_grad():\n",
    "    label = dset[index][2]\n",
    "    # original image prediction\n",
    "    pred_original, acc_original = classify_image(dset[index][0][None].cuda(), classifier, label)\n",
    "    show.a(['original: %0.2f %s' % (pred_original[0], get_symbol(acc_original[0])),\n",
    "            renormalize.as_image(dset[index][0]).resize((256, 256), Image.ANTIALIAS)])\n",
    "    \n",
    "    # gan reconstruction prediction\n",
    "    latent = dset[index][1][None].cuda()\n",
    "    reconstruction = generator.decode(latent)\n",
    "    postprocessed_rec, pred_rec, acc_rec = classify_from_gan(reconstruction, classifier, tensor_transform_val, label)\n",
    "    show.a(['reconstruction %0.2f %s' % (pred_rec[0], get_symbol(acc_rec[0])),\n",
    "            renormalize.as_image(postprocessed_rec[0]).resize((256, 256), Image.ANTIALIAS)])\n",
    "    show.flush()\n",
    "    \n",
    "    # stylemix fine\n",
    "    mix_latent = generator.seed2w(n=4, seed=np.random.randint(1000))\n",
    "    perturbed_im = generator.perturb_stylemix(latent, 'fine', mix_latent,n=4)\n",
    "    postprocessed_preturbed, pred_perturbed, acc_perturbed = classify_from_gan(\n",
    "            perturbed_im, classifier, tensor_transform_ensemble, label)\n",
    "    for i in range(len(perturbed_im)):\n",
    "        show.a(['stylemix fine %0.2f %s' % (pred_perturbed[i],get_symbol(acc_perturbed[i])),\n",
    "                renormalize.as_image(postprocessed_preturbed[i]).resize((150, 150), Image.ANTIALIAS)])\n",
    "    show.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-ensembling",
   "language": "python",
   "name": "gan-ensembling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}